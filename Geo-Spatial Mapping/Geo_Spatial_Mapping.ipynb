{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75gXr9A7fxeC"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestNeighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwU_z_JUFHis"
      },
      "outputs": [],
      "source": [
        "def run_dashboard(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Launch a Streamlit dashboard that provides interactive filtering of crime data,\n",
        "    displays summary statistics, and shows geo-spatial maps.\n",
        "    \"\"\"\n",
        "    import streamlit as st\n",
        "    from streamlit_folium import st_folium\n",
        "\n",
        "    st.title(\"CityX Crime Analysis Dashboard\")\n",
        "    st.sidebar.header(\"Filters\")\n",
        "    district_filter = st.sidebar.multiselect(\"Select District(s):\",\n",
        "                                             options=df[\"PdDistrict\"].unique(),\n",
        "                                             default=df[\"PdDistrict\"].unique())\n",
        "    crime_filter = st.sidebar.multiselect(\"Select Crime Category:\",\n",
        "                                          options=df[\"Category\"].unique(),\n",
        "                                          default=df[\"Category\"].unique())\n",
        "\n",
        "    filtered_df = df[(df[\"PdDistrict\"].isin(district_filter)) & (df[\"Category\"].isin(crime_filter))]\n",
        "\n",
        "    st.subheader(\"Crime Data Overview\")\n",
        "    st.write(filtered_df.head())\n",
        "    st.write(f\"Total crimes: {len(filtered_df)}\")\n",
        "\n",
        "    st.subheader(\"Crime Clusters Map\")\n",
        "    create_cluster_map(filtered_df, output_html=\"temp_cluster_map.html\")\n",
        "    st_folium(folium.Map(), width=700, height=500)\n",
        "    from google.colab import files\n",
        "    files.download('temp_cluster_map.html')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmBA78m0FRzP"
      },
      "outputs": [],
      "source": [
        "def create_heatmap(df: pd.DataFrame, output_html: str = \"crime_heatmap.html\"):\n",
        "    \"\"\"Generate and save an interactive heatmap of crime incidents using Folium.\"\"\"\n",
        "    center_coords = [df[\"Latitude\"].mean(), df[\"Longitude\"].mean()]\n",
        "    crime_map = folium.Map(location=center_coords, zoom_start=12)\n",
        "    heat_data = df[[\"Latitude\", \"Longitude\"]].values.tolist()\n",
        "    HeatMap(heat_data, radius=15, blur=10).add_to(crime_map)\n",
        "    crime_map.save(output_html)\n",
        "    print(f\"Heatmap saved as {output_html}\")\n",
        "\n",
        "\n",
        "\n",
        "def create_cluster_map(df: pd.DataFrame, output_html: str = \"crime_clusters.html\"):\n",
        "    \"\"\"Generate and save an interactive cluster map using Folium with DBSCAN hotspot detection.\"\"\"\n",
        "    # Clean data\n",
        "    df_clean = df.dropna(subset=[\"Latitude\", \"Longitude\"])\n",
        "    center_coords = [df_clean[\"Latitude\"].mean(), df_clean[\"Longitude\"].mean()]\n",
        "\n",
        "    # Create base map\n",
        "    cluster_map = folium.Map(location=center_coords, zoom_start=12, tiles=\"cartodbpositron\")\n",
        "\n",
        "    # Create marker clusters by severity\n",
        "    severity_groups = df_clean.groupby('Severity')\n",
        "    for severity, group in severity_groups:\n",
        "        marker_cluster = MarkerCluster(name=f\"Severity {severity}\").add_to(cluster_map)\n",
        "\n",
        "        # Determine color based on severity\n",
        "        if severity >= 5:\n",
        "            color = 'red'\n",
        "            icon = 'exclamation-triangle'\n",
        "        elif severity >= 4:\n",
        "            color = 'purple'\n",
        "            icon = 'exclamation-triangle'\n",
        "        elif severity >= 3:\n",
        "            color = 'orange'\n",
        "            icon = 'info-sign'\n",
        "        elif severity >= 2:\n",
        "            color = 'blue'\n",
        "            icon = 'info-sign'\n",
        "        else:\n",
        "            color = 'green'\n",
        "            icon = 'info-sign'\n",
        "\n",
        "        # Add markers for each crime in this severity group\n",
        "        for idx, row in group.iterrows():\n",
        "            popup_content = (f\"<b>Category:</b> {row['Category']}<br>\"\n",
        "                            f\"<b>Date:</b> {row['Dates']}<br>\"\n",
        "                            f\"<b>Severity:</b> {severity}<br>\"\n",
        "                            f\"<b>Address:</b> {row.get('Address', 'Unknown')}\")\n",
        "            folium.Marker(\n",
        "                location=[row[\"Latitude\"], row[\"Longitude\"]],\n",
        "                popup=folium.Popup(popup_content, max_width=300),\n",
        "                icon=folium.Icon(color=color, icon=icon)\n",
        "            ).add_to(marker_cluster)\n",
        "\n",
        "    # Add heat map layer\n",
        "    heat_data = [[row['Latitude'], row['Longitude']] for idx, row in df_clean.iterrows()]\n",
        "    HeatMap(heat_data).add_to(cluster_map)\n",
        "\n",
        "    # Identify hotspots using DBSCAN clustering\n",
        "    coords = df_clean[['Latitude', 'Longitude']].values\n",
        "    # Standardize the data\n",
        "    coords_scaled = StandardScaler().fit_transform(coords)\n",
        "\n",
        "    # Precompute neighbors with sparse output\n",
        "    neighbors = NearestNeighbors(n_neighbors=4, radius=0.1, metric='euclidean')\n",
        "    neighbors.fit(coords_scaled)\n",
        "\n",
        "    # Use precomputed sparse distance matrix for DBSCAN\n",
        "    distance_matrix = neighbors.kneighbors_graph(coords_scaled, mode='distance')\n",
        "\n",
        "    # Fit DBSCAN with the sparse distance matrix\n",
        "    db = DBSCAN(eps=0.1, min_samples=4, metric='precomputed').fit(distance_matrix)\n",
        "    df_clean['cluster'] = db.labels_\n",
        "\n",
        "    # Highlight cluster centers as hotspots\n",
        "    clusters = {}\n",
        "    for cluster_id in set(db.labels_):\n",
        "        if cluster_id != -1:  # Skip noise points\n",
        "            mask = df_clean['cluster'] == cluster_id\n",
        "            clusters[cluster_id] = {\n",
        "                'center': [df_clean.loc[mask, 'Latitude'].mean(), df_clean.loc[mask, 'Longitude'].mean()],\n",
        "                'count': mask.sum()\n",
        "            }\n",
        "\n",
        "    # Add hotspot markers\n",
        "    for cluster_id, info in clusters.items():\n",
        "        folium.CircleMarker(\n",
        "            location=info['center'],\n",
        "            radius=10,\n",
        "            popup=f'Hotspot #{cluster_id}: {info[\"count\"]} incidents',\n",
        "            color='black',\n",
        "            fill=True,\n",
        "            fill_color='yellow',\n",
        "            fill_opacity=0.7\n",
        "        ).add_to(cluster_map)\n",
        "\n",
        "    # Add layer control\n",
        "    folium.LayerControl().add_to(cluster_map)\n",
        "\n",
        "    # Save the map\n",
        "    cluster_map.save(output_html)\n",
        "    print(f\"Cluster map saved as {output_html}\")\n",
        "\n",
        "    return cluster_map\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrXZh7A_WvPD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def create_cluster_map(df: pd.DataFrame, output_html: str = \"crime_clusters.html\"):\n",
        "    \"\"\"Generate and save an interactive cluster map using Folium with DBSCAN hotspot detection.\n",
        "       This version uses GeoJSON for marker data to reduce the overall file size.\n",
        "    \"\"\"\n",
        "    # Clean data\n",
        "    df_clean = df.dropna(subset=[\"Latitude\", \"Longitude\"])\n",
        "    center_coords = [df_clean[\"Latitude\"].mean(), df_clean[\"Longitude\"].mean()]\n",
        "\n",
        "    # Create base map\n",
        "    cluster_map = folium.Map(location=center_coords, zoom_start=12, tiles=\"cartodbpositron\")\n",
        "\n",
        "    # Create GeoDataFrame from the cleaned dataframe\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        df_clean,\n",
        "        geometry=gpd.points_from_xy(df_clean['Longitude'], df_clean['Latitude'])\n",
        "    )\n",
        "\n",
        "    # keep Category, Dates, Severity, and Address\n",
        "    gdf = gdf[['Category', 'Dates', 'Severity', 'Address', 'geometry']]\n",
        "\n",
        "    # Save the GeoDataFrame as a GeoJSON file\n",
        "    geojson_filename = 'crime_data.geojson'\n",
        "    gdf.to_file(geojson_filename, driver='GeoJSON')\n",
        "\n",
        "    # Add GeoJSON to the Folium map (this will load the data more efficiently)\n",
        "    folium.GeoJson(\n",
        "        geojson_filename,\n",
        "        name=\"Crime Data\"\n",
        "    ).add_to(cluster_map)\n",
        "\n",
        "    # Add heat map layer for additional context (using only coordinates)\n",
        "    heat_data = [[row['Latitude'], row['Longitude']] for idx, row in df_clean.iterrows()]\n",
        "    HeatMap(heat_data).add_to(cluster_map)\n",
        "\n",
        "    # Identify hotspots using DBSCAN clustering\n",
        "    coords = df_clean[['Latitude', 'Longitude']].values\n",
        "    # Standardize the data\n",
        "    coords_scaled = StandardScaler().fit_transform(coords)\n",
        "\n",
        "    # Precompute neighbors with sparse output\n",
        "    neighbors = NearestNeighbors(n_neighbors=4, radius=0.1, metric='euclidean')\n",
        "    neighbors.fit(coords_scaled)\n",
        "\n",
        "    # Use precomputed sparse distance matrix for DBSCAN\n",
        "    distance_matrix = neighbors.kneighbors_graph(coords_scaled, mode='distance')\n",
        "\n",
        "    # Fit DBSCAN with the sparse distance matrix\n",
        "    db = DBSCAN(eps=0.1, min_samples=4, metric='precomputed').fit(distance_matrix)\n",
        "    df_clean['cluster'] = db.labels_\n",
        "\n",
        "    clusters = {}\n",
        "    for cluster_id in set(db.labels_):\n",
        "        if cluster_id != -1:  # Skip noise points\n",
        "            mask = df_clean['cluster'] == cluster_id\n",
        "            clusters[cluster_id] = {\n",
        "                'center': [df_clean.loc[mask, 'Latitude'].mean(), df_clean.loc[mask, 'Longitude'].mean()],\n",
        "                'count': mask.sum()\n",
        "            }\n",
        "\n",
        "    # Add hotspot markers as circle markers\n",
        "    for cluster_id, info in clusters.items():\n",
        "        folium.CircleMarker(\n",
        "            location=info['center'],\n",
        "            radius=10,\n",
        "            popup=f'Hotspot #{cluster_id}: {info[\"count\"]} incidents',\n",
        "            color='black',\n",
        "            fill=True,\n",
        "            fill_color='yellow',\n",
        "            fill_opacity=0.7\n",
        "        ).add_to(cluster_map)\n",
        "\n",
        "    # Add layer control\n",
        "    folium.LayerControl().add_to(cluster_map)\n",
        "\n",
        "    # Save the map to HTML\n",
        "    cluster_map.save(output_html)\n",
        "    print(f\"Cluster map saved as {output_html}\")\n",
        "\n",
        "    return cluster_map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgWxwDg7FgiH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "from folium.plugins import HeatMap, MarkerCluster\n",
        "from streamlit_folium import st_folium\n",
        "\n",
        "df = pd.read_csv('cleaned_data.csv')\n",
        "\n",
        "df = df.rename(columns={\n",
        "    'Latitude (Y)': 'Longitude',  # Contains longitude values (-122.5 to -120.5)\n",
        "    'Longitude (X)': 'Latitude'   # Contains latitude values (37.7 to 90.0)\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZhSfIapFEUh"
      },
      "outputs": [],
      "source": [
        "# Create geo-spatial visualizations\n",
        "create_heatmap(df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgG5fAgoXaSb",
        "outputId": "3acbd96e-ad42-4b32-b00c-9702fc5689af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyogrio/geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
            "  write(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py:248: EfficiencyWarning: Precomputed sparse input was not sorted by row values. Use the function sklearn.neighbors.sort_graph_by_row_values to sort the input by row values, with warn_when_not_sorted=False to remove this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cluster map saved as crime_clusters.html\n",
            "Buffered data was truncated after reaching the output size limit."
          ]
        }
      ],
      "source": [
        "create_cluster_map(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "rRFjKik4Gwck",
        "outputId": "795344d6-6b52-4323-e9b1-70f5e68c16c2",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-31 13:08:44.632 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.634 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.697 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.698 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.699 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.700 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.700 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.768 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.769 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.770 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.770 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.771 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.844 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.844 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.913 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.916 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.916 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-03-31 13:08:44.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'create_cluster_map' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9e12f201f820>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Uncomment the next line to run the interactive dashboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_dashboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-297f834ca811>\u001b[0m in \u001b[0;36mrun_dashboard\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Crime Clusters Map\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mcreate_cluster_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_html\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"temp_cluster_map.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mst_folium\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'create_cluster_map' is not defined"
          ]
        }
      ],
      "source": [
        "run_dashboard(df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}